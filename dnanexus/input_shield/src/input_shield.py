#!/usr/bin/env python
# input_shield 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import logging
import re
import dxpy
import common

KEYFILE = 'keypairs.json'
DEFAULT_SERVER = 'https://www.encodeproject.org'
S3_SERVER = 's3://encode-files/'
DATA_CACHE_PROJECT = None  # if specified, look in that project for ENCFF files

logger = logging.getLogger(__name__)
logger.addHandler(dxpy.DXLogHandler())
logger.propagate = False


def resolve_project(identifier, privs='r'):
    logger.debug("In resolve_project with identifier %s" %(identifier))
    project = dxpy.find_one_project(name=identifier, level='VIEW', name_mode='exact', return_handler=True, zero_ok=True)
    if project == None:
        try:
            project = dxpy.get_handler(identifier)
        except:
            logger.error('Could not find a unique project with name or id %s' %(identifier))
            raise ValueError(identifier)
    logger.debug('Project %s access level is %s' %(project.name, project.describe()['level']))
    if privs == 'w' and project.describe()['level'] == 'VIEW':
        logger.error('Output project %s is read-only' %(identifier))
        raise ValueError(identifier)
    return project


def resolve_folder(project, identifier):
    if not identifier.startswith('/'):
        identifier = '/' + identifier
    try:
        project_id = project.list_folder(identifier)
    except:
        try:
            project_id = project.new_folder(identifier, parents=True)
        except:
            logger.error("Cannot create folder %s in project %s" %(identifier, project.name))
            raise ValueError('%s:%s' %(project.name, identifier))
        else:
            logger.info("New folder %s created in project %s" %(identifier, project.name))
    return identifier


def resolve_accession(accession, key):
    logger.debug("Looking for accession %s" %(accession))

    if not re.match(r'''^ENCFF\d{3}[A-Z]{3}''', accession):
        logger.warning("%s is not a valid accession format" %(accession))
        return None

    if DATA_CACHE_PROJECT:
        logger.debug('Looking for cache project %s' %(DATA_CACHE_PROJECT))
        try:
            project_handler = resolve_project(DATA_CACHE_PROJECT)
            snapshot_project = project_handler
        except:
            logger.error("Cannot find cache project %s" %(DATA_CACHE_PROJECT))
            snapshot_project = None

        logger.debug('Cache project: %s' %(snapshot_project))

        if snapshot_project:
            try:
                accession_search = accession + '*'
                logger.debug('Looking recursively for %s in %s' %(accession_search, snapshot_project.name))
                file_handler = dxpy.find_one_data_object(
                    name=accession_search, name_mode='glob', more_ok=False, classname='file', recurse=True, return_handler=True,
                    folder='/', project=snapshot_project.get_id())
                logger.debug('Got file handler for %s' %(file_handler.name))
                return file_handler
            except:
                logger.debug("Cannot find accession %s in project %s" %(accession, snapshot_project))

    # we're here because we couldn't find the cache or couldn't find the file in the cache, so look in AWS

    dx_file = common.s3cp(accession, key) #this returns a link to the file in the applet's project context

    if not dx_file:
        logger.warning('Cannot find %s.  Giving up.' %(accession))
        return None
    else:
        return dx_file


def resolve_file(identifier, key):
    logger.debug("resolve_file: %s" %(identifier))

    assert identifier, "No file identifier passed to resolve_file"

    m = re.match(r'''^([\w\-\ \.]+):([\w\-\ /\.]+)''', identifier)
    if m: #fully specified with project:path
        project_identifier = m.group(1)
        file_identifier = m.group(2)
    else:
        logger.debug("Defaulting to the current project")
        project_identifier = dxpy.WORKSPACE_ID
        file_identifier = identifier    

    project = resolve_project(project_identifier)
    logger.debug("Got project %s" %(project.name))
    logger.debug("Now looking for file %s" %(file_identifier))

    m = re.match(r'''(^[\w\-\ /\.]+)/([\w\-\ \.]+)''', file_identifier)
    if m:
        folder_name = m.group(1)
        if not folder_name.startswith('/'):
            folder_name = '/' + folder_name
        file_name = m.group(2)
    else:
        folder_name = '/'
        file_name = file_identifier

    logger.debug("Looking for file %s in folder %s" %(file_name, folder_name))

    try:
        file_handler = dxpy.find_one_data_object(name=file_name, folder=folder_name, project=project.get_id(),
            more_ok=False, zero_ok=False, return_handler=True)
    except:
        logger.debug('%s not found in project %s folder %s' %(file_name, project.get_id(), folder_name))
        try: #maybe it's just  filename in the default workspace
            file_handler = dxpy.DXFile(dxid=identifier, mode='r')
        except:
            logger.debug('%s not found as a dxid' %(identifier))
            file_handler = resolve_accession(identifier, key)

    assert file_handler, "Failed to resolve file identifier %s" %(identifier)
    logger.debug("Resolved file identifier %s to %s" %(identifier, file_handler.name))
    return file_handler


def pooled(files):
    pool_applet = dxpy.find_one_data_object(
        classname='applet', name='pool', project=dxpy.PROJECT_CONTEXT_ID,
        zero_ok=False, more_ok=False, return_handler=True)
    logger.debug('input files:%s' %(files))
    logger.debug('input file ids:%s' %([dxf.get_id() for dxf in files]))
    logger.debug('input files dxlinks:%s' %([dxpy.dxlink(dxf) for dxf in files]))
    pool_subjob = pool_applet.run({"inputs": [dxpy.dxlink(dxf) for dxf in files]})
    pooled_file = pool_subjob.get_output_ref("pooled")
    return pooled_file


@dxpy.entry_point('main')
def main(reads1, reads2, crop_length, reference_tar,
         bwa_aln_params, bwa_version, samtools_version, key, debug):

    # reads1 and reads2 are expected to be an arrays of file identifiers
    # indentifiers can be DNAnexus files or ENCODE file accession numbers
    # For SE, reads2 is empty
    # For PE, len(reads1) = len(reads2)
    # Multiple PE pairs or SE files are just catted before mapping
    # Error on mixed SE/PE - although this can be implemented as just a
    # "" entry at that position in reads2 array
    # TODO: Add option to down-sample mixed PE/SE to SE

    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    logger.info("reads1: %s" % (reads1))
    logger.info("reads2: %s" % (reads2))

    if reads2:
        paired_end = True
        assert len(reads1) == len(reads2), "Paired-end and unequal numbers of read1 and read2 identifiers: %s %s" %(reads1, reads2)
    else:
        paired_end = False

    reads1_files = [resolve_file(read, key) for read in reads1]

    if paired_end:
        reads2_files = [resolve_file(read, key) for read in reads2]
    else:
        reads2_files = []

    # pooling multiple fastqs
    if len(reads1_files) > 1:
        reads1_file = pooled(reads1_files)
    else:
        reads1_file = reads1_files[0]

    if len(reads2_files) > 1:
        reads2_file = pooled(reads2_files)
    elif len(reads2_files) == 1:
        reads2_file = reads2_files[0]
    else:
        reads2_file = None

    reference_tar_file = resolve_file(reference_tar, key)

    logger.info('Resolved reads1 to %s', reads1_file)
    if reads2_file:
        logger.info('Resolved reads2 to %s', reads2_file)
    logger.info('Resolved reference_tar to %s', reference_tar_file)

    output = {
        "reads1": reads1_file,
        "reference_tar": reference_tar_file,
        "crop_length": crop_length,
        "bwa_aln_params": bwa_aln_params,
        "bwa_version": bwa_version,
        "samtools_version": samtools_version
    }
    if reads2_file:
        output.update({"reads2": reads2_file})

    logger.info('Exiting with output: %s' % (output))

    return output

dxpy.run()
